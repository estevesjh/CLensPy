{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f16b238",
   "metadata": {},
   "source": [
    "# CLensPy Profile Fitting Demo\n",
    "\n",
    "This notebook demonstrates how to fit NFW profiles to simulated weak lensing data using the CLensPy package.\n",
    "\n",
    "## Overview\n",
    "\n",
    "We will:\n",
    "1. Generate synthetic weak lensing data\n",
    "2. Fit NFW profiles to the data\n",
    "3. Estimate uncertainties using MCMC\n",
    "4. Visualize the results\n",
    "\n",
    "This is a practical example of how CLensPy can be used for real weak lensing analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9759b3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as opt\n",
    "from scipy.stats import chi2\n",
    "import emcee  # For MCMC sampling\n",
    "import corner  # For corner plots\n",
    "\n",
    "# Import CLensPy modules\n",
    "from clenspy.profiles import NFWProfile\n",
    "from clenspy.lensing import delta_sigma_nfw, shear_profile\n",
    "from clenspy.utils import angular_to_physical, physical_to_angular\n",
    "\n",
    "# Set up matplotlib\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c8122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "np.random.seed(42)  # For reproducible results\n",
    "\n",
    "# True halo parameters (what we're trying to recover)\n",
    "M200_true = 2e14  # Solar masses\n",
    "c200_true = 6.0   # Concentration\n",
    "z_lens = 0.25     # Lens redshift\n",
    "z_source = 1.2    # Source redshift\n",
    "\n",
    "print(f\"True parameters:\")\n",
    "print(f\"M200 = {M200_true:.1e} Msun\")\n",
    "print(f\"c200 = {c200_true}\")\n",
    "print(f\"z_lens = {z_lens}\")\n",
    "print(f\"z_source = {z_source}\")\n",
    "\n",
    "# Define radial bins for observations\n",
    "r_min, r_max = 0.2, 3.0  # Mpc\n",
    "n_bins = 15\n",
    "r_centers = np.logspace(np.log10(r_min), np.log10(r_max), n_bins)\n",
    "\n",
    "# Calculate true delta sigma profile\n",
    "delta_sigma_true = delta_sigma_nfw(r_centers, M200_true, c200_true, z_lens, z_source)\n",
    "\n",
    "# Add realistic noise\n",
    "# Typical weak lensing errors scale roughly as 1/sqrt(N_pairs)\n",
    "relative_error = 0.15  # 15% typical error\n",
    "noise_level = relative_error * delta_sigma_true\n",
    "delta_sigma_obs = delta_sigma_true + np.random.normal(0, noise_level)\n",
    "delta_sigma_err = noise_level\n",
    "\n",
    "print(f\"\\nGenerated {n_bins} data points with {relative_error*100}% noise\")\n",
    "print(f\"Radial range: {r_min:.1f} - {r_max:.1f} Mpc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31aa287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the synthetic data\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot true profile\n",
    "r_fine = np.logspace(np.log10(0.1), np.log10(5.0), 100)\n",
    "delta_sigma_fine = delta_sigma_nfw(r_fine, M200_true, c200_true, z_lens, z_source)\n",
    "ax.loglog(r_fine, delta_sigma_fine, 'k-', linewidth=2, label='True profile')\n",
    "\n",
    "# Plot synthetic observations\n",
    "ax.errorbar(r_centers, delta_sigma_obs, yerr=delta_sigma_err, \n",
    "           fmt='ro', markersize=6, capsize=3, capthick=1.5, \n",
    "           label='Synthetic observations')\n",
    "\n",
    "ax.set_xlabel('Radius [Mpc]')\n",
    "ax.set_ylabel('Δσ [M☉/Mpc²]')\n",
    "ax.set_title('Synthetic Weak Lensing Data')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "ax.set_xlim(0.1, 5.0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Synthetic data plotted successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f991e46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define chi-squared function for fitting\n",
    "def chi_squared(params, r_data, delta_sigma_data, delta_sigma_err):\n",
    "    \"\"\"\n",
    "    Calculate chi-squared for NFW profile fit.\n",
    "    \n",
    "    Parameters:\n",
    "    params: [log10(M200), c200]\n",
    "    \"\"\"\n",
    "    log10_M200, c200 = params\n",
    "    M200 = 10**log10_M200\n",
    "    \n",
    "    # Check parameter bounds\n",
    "    if M200 < 1e12 or M200 > 1e16:  # Reasonable mass range\n",
    "        return np.inf\n",
    "    if c200 < 1.0 or c200 > 20.0:   # Reasonable concentration range\n",
    "        return np.inf\n",
    "    \n",
    "    # Calculate model prediction\n",
    "    try:\n",
    "        delta_sigma_model = delta_sigma_nfw(r_data, M200, c200, z_lens, z_source)\n",
    "        chi2 = np.sum(((delta_sigma_data - delta_sigma_model) / delta_sigma_err)**2)\n",
    "        return chi2\n",
    "    except:\n",
    "        return np.inf\n",
    "\n",
    "# Perform maximum likelihood fit\n",
    "def fit_nfw_profile(r_data, delta_sigma_data, delta_sigma_err):\n",
    "    \"\"\"Fit NFW profile using scipy optimization.\"\"\"\n",
    "    \n",
    "    # Initial guess\n",
    "    M200_guess = 1e14\n",
    "    c200_guess = 5.0\n",
    "    initial_params = [np.log10(M200_guess), c200_guess]\n",
    "    \n",
    "    # Minimize chi-squared\n",
    "    result = opt.minimize(chi_squared, initial_params, \n",
    "                         args=(r_data, delta_sigma_data, delta_sigma_err),\n",
    "                         method='Nelder-Mead')\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Perform the fit\n",
    "print(\"Fitting NFW profile to synthetic data...\")\n",
    "fit_result = fit_nfw_profile(r_centers, delta_sigma_obs, delta_sigma_err)\n",
    "\n",
    "# Extract best-fit parameters\n",
    "log10_M200_best, c200_best = fit_result.x\n",
    "M200_best = 10**log10_M200_best\n",
    "chi2_best = fit_result.fun\n",
    "ndof = len(r_centers) - 2  # degrees of freedom\n",
    "reduced_chi2 = chi2_best / ndof\n",
    "\n",
    "print(f\"\\nBest-fit results:\")\n",
    "print(f\"M200 = {M200_best:.2e} Msun (true: {M200_true:.2e})\")\n",
    "print(f\"c200 = {c200_best:.2f} (true: {c200_true:.2f})\")\n",
    "print(f\"χ²/dof = {reduced_chi2:.2f}\")\n",
    "print(f\"Success: {fit_result.success}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354d214e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot best-fit model\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 10), \n",
    "                               gridspec_kw={'height_ratios': [3, 1]})\n",
    "\n",
    "# Main plot\n",
    "r_fine = np.logspace(np.log10(0.1), np.log10(5.0), 100)\n",
    "\n",
    "# True profile\n",
    "delta_sigma_true_fine = delta_sigma_nfw(r_fine, M200_true, c200_true, z_lens, z_source)\n",
    "ax1.loglog(r_fine, delta_sigma_true_fine, 'k-', linewidth=2, label='True profile')\n",
    "\n",
    "# Best-fit profile\n",
    "delta_sigma_fit = delta_sigma_nfw(r_fine, M200_best, c200_best, z_lens, z_source)\n",
    "ax1.loglog(r_fine, delta_sigma_fit, 'b--', linewidth=2, label='Best fit')\n",
    "\n",
    "# Data points\n",
    "ax1.errorbar(r_centers, delta_sigma_obs, yerr=delta_sigma_err, \n",
    "           fmt='ro', markersize=6, capsize=3, capthick=1.5, \n",
    "           label='Data')\n",
    "\n",
    "ax1.set_ylabel('Δσ [M☉/Mpc²]')\n",
    "ax1.set_title(f'NFW Profile Fit (χ²/dof = {reduced_chi2:.2f})')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "ax1.set_xlim(0.1, 5.0)\n",
    "\n",
    "# Residuals plot\n",
    "delta_sigma_fit_data = delta_sigma_nfw(r_centers, M200_best, c200_best, z_lens, z_source)\n",
    "residuals = (delta_sigma_obs - delta_sigma_fit_data) / delta_sigma_err\n",
    "\n",
    "ax2.semilogx(r_centers, residuals, 'ro', markersize=6)\n",
    "ax2.axhline(0, color='k', linestyle='-', alpha=0.5)\n",
    "ax2.axhline(1, color='k', linestyle='--', alpha=0.3)\n",
    "ax2.axhline(-1, color='k', linestyle='--', alpha=0.3)\n",
    "ax2.set_xlabel('Radius [Mpc]')\n",
    "ax2.set_ylabel('Residuals [σ]')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_xlim(0.1, 5.0)\n",
    "ax2.set_ylim(-3, 3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Best-fit model plotted successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6868fcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCMC analysis for uncertainty estimation\n",
    "def log_probability(params, r_data, delta_sigma_data, delta_sigma_err):\n",
    "    \"\"\"Log probability function for MCMC sampling.\"\"\"\n",
    "    \n",
    "    log10_M200, c200 = params\n",
    "    M200 = 10**log10_M200\n",
    "    \n",
    "    # Priors (log-uniform for mass, uniform for concentration)\n",
    "    if not (12.0 <= log10_M200 <= 16.0):  # 10^12 to 10^16 Msun\n",
    "        return -np.inf\n",
    "    if not (1.0 <= c200 <= 20.0):\n",
    "        return -np.inf\n",
    "    \n",
    "    # Calculate chi-squared\n",
    "    try:\n",
    "        delta_sigma_model = delta_sigma_nfw(r_data, M200, c200, z_lens, z_source)\n",
    "        chi2 = np.sum(((delta_sigma_data - delta_sigma_model) / delta_sigma_err)**2)\n",
    "        return -0.5 * chi2\n",
    "    except:\n",
    "        return -np.inf\n",
    "\n",
    "# Set up MCMC\n",
    "print(\"Setting up MCMC sampling...\")\n",
    "\n",
    "ndim = 2  # number of parameters\n",
    "nwalkers = 32  # number of MCMC walkers\n",
    "nsteps = 2000  # number of steps per walker\n",
    "\n",
    "# Initialize walkers around best-fit values\n",
    "pos = []\n",
    "for i in range(nwalkers):\n",
    "    # Add small random perturbations to best-fit parameters\n",
    "    log10_M200_init = log10_M200_best + 0.1 * np.random.randn()\n",
    "    c200_init = c200_best + 0.5 * np.random.randn()\n",
    "    \n",
    "    # Ensure within bounds\n",
    "    log10_M200_init = np.clip(log10_M200_init, 12.0, 16.0)\n",
    "    c200_init = np.clip(c200_init, 1.0, 20.0)\n",
    "    \n",
    "    pos.append([log10_M200_init, c200_init])\n",
    "\n",
    "pos = np.array(pos)\n",
    "\n",
    "# Set up the sampler\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, log_probability,\n",
    "                               args=(r_centers, delta_sigma_obs, delta_sigma_err))\n",
    "\n",
    "print(f\"Running MCMC with {nwalkers} walkers for {nsteps} steps...\")\n",
    "print(\"This may take a moment...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cbddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run MCMC\n",
    "sampler.run_mcmc(pos, nsteps, progress=True)\n",
    "\n",
    "# Analyze results\n",
    "print(\"MCMC completed!\")\n",
    "\n",
    "# Remove burn-in (first 500 steps)\n",
    "burn_in = 500\n",
    "samples = sampler.get_chain(discard=burn_in, flat=True)\n",
    "\n",
    "# Calculate statistics\n",
    "log10_M200_mcmc = samples[:, 0]\n",
    "c200_mcmc = samples[:, 1]\n",
    "M200_mcmc = 10**log10_M200_mcmc\n",
    "\n",
    "# Parameter estimates (median and 68% confidence intervals)\n",
    "M200_median = np.median(M200_mcmc)\n",
    "M200_lower = np.percentile(M200_mcmc, 16)\n",
    "M200_upper = np.percentile(M200_mcmc, 84)\n",
    "\n",
    "c200_median = np.median(c200_mcmc)\n",
    "c200_lower = np.percentile(c200_mcmc, 16)\n",
    "c200_upper = np.percentile(c200_mcmc, 84)\n",
    "\n",
    "print(\"\\nMCMC Results (median ± 68% confidence interval):\")\n",
    "print(f\"M200 = {M200_median:.2e} +{M200_upper-M200_median:.2e} -{M200_median-M200_lower:.2e} Msun\")\n",
    "print(f\"c200 = {c200_median:.2f} +{c200_upper-c200_median:.2f} -{c200_median-c200_lower:.2f}\")\n",
    "print(f\"\\nTrue values:\")\n",
    "print(f\"M200 = {M200_true:.2e} Msun\")\n",
    "print(f\"c200 = {c200_true:.2f}\")\n",
    "\n",
    "# Check convergence\n",
    "print(f\"\\nAcceptance fraction: {np.mean(sampler.acceptance_fraction):.3f}\")\n",
    "print(f\"Number of samples: {len(samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c318823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create corner plot to visualize parameter correlations\n",
    "fig = corner.corner(samples, labels=[r'$\\log_{10}(M_{200})$', r'$c_{200}$'],\n",
    "                   truths=[np.log10(M200_true), c200_true],\n",
    "                   truth_color='red', show_titles=True, title_kwargs={'fontsize': 12})\n",
    "\n",
    "plt.suptitle('Parameter Constraints from MCMC', y=1.02, fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# Plot MCMC chains to check convergence\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "# M200 chain\n",
    "axes[0].plot(sampler.get_chain()[:, :, 0].T, alpha=0.3, color='blue')\n",
    "axes[0].axhline(np.log10(M200_true), color='red', linestyle='--', label='True value')\n",
    "axes[0].axvline(burn_in, color='black', linestyle=':', alpha=0.7, label='Burn-in')\n",
    "axes[0].set_ylabel(r'$\\log_{10}(M_{200})$')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# c200 chain\n",
    "axes[1].plot(sampler.get_chain()[:, :, 1].T, alpha=0.3, color='green')\n",
    "axes[1].axhline(c200_true, color='red', linestyle='--', label='True value')\n",
    "axes[1].axvline(burn_in, color='black', linestyle=':', alpha=0.7, label='Burn-in')\n",
    "axes[1].set_ylabel(r'$c_{200}$')\n",
    "axes[1].set_xlabel('Step number')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('MCMC Chains', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Corner plot and chain diagnostics created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b1f6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary plot with uncertainty bands\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Fine radial grid for smooth curves\n",
    "r_fine = np.logspace(np.log10(0.1), np.log10(5.0), 100)\n",
    "\n",
    "# True profile\n",
    "delta_sigma_true_fine = delta_sigma_nfw(r_fine, M200_true, c200_true, z_lens, z_source)\n",
    "ax.loglog(r_fine, delta_sigma_true_fine, 'k-', linewidth=3, label='True profile', zorder=3)\n",
    "\n",
    "# Best-fit profile\n",
    "delta_sigma_fit = delta_sigma_nfw(r_fine, M200_best, c200_best, z_lens, z_source)\n",
    "ax.loglog(r_fine, delta_sigma_fit, 'b--', linewidth=2, label='Best fit (ML)', zorder=2)\n",
    "\n",
    "# MCMC median profile\n",
    "delta_sigma_median = delta_sigma_nfw(r_fine, M200_median, c200_median, z_lens, z_source)\n",
    "ax.loglog(r_fine, delta_sigma_median, 'orange', linewidth=2, label='MCMC median', zorder=2)\n",
    "\n",
    "# Calculate uncertainty band from MCMC samples (use subset for speed)\n",
    "n_samples_plot = 100\n",
    "indices = np.random.choice(len(samples), n_samples_plot, replace=False)\n",
    "delta_sigma_samples = []\n",
    "\n",
    "for i in indices:\n",
    "    M200_sample = 10**samples[i, 0]\n",
    "    c200_sample = samples[i, 1]\n",
    "    ds_sample = delta_sigma_nfw(r_fine, M200_sample, c200_sample, z_lens, z_source)\n",
    "    delta_sigma_samples.append(ds_sample)\n",
    "\n",
    "delta_sigma_samples = np.array(delta_sigma_samples)\n",
    "\n",
    "# Calculate percentiles for uncertainty band\n",
    "ds_16 = np.percentile(delta_sigma_samples, 16, axis=0)\n",
    "ds_84 = np.percentile(delta_sigma_samples, 84, axis=0)\n",
    "\n",
    "# Plot uncertainty band\n",
    "ax.fill_between(r_fine, ds_16, ds_84, alpha=0.3, color='orange', \n",
    "               label='68% confidence', zorder=1)\n",
    "\n",
    "# Data points\n",
    "ax.errorbar(r_centers, delta_sigma_obs, yerr=delta_sigma_err, \n",
    "           fmt='ro', markersize=8, capsize=4, capthick=2, \n",
    "           label='Synthetic data', zorder=4)\n",
    "\n",
    "ax.set_xlabel('Radius [Mpc]', fontsize=14)\n",
    "ax.set_ylabel('Δσ [M☉/Mpc²]', fontsize=14)\n",
    "ax.set_title('NFW Profile Fitting Results', fontsize=16)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(fontsize=12)\n",
    "ax.set_xlim(0.1, 5.0)\n",
    "\n",
    "# Add parameter info as text\n",
    "info_text = f\"\"\"Best-fit parameters:\n",
    "M₂₀₀ = {M200_median:.2e} Msun\n",
    "c₂₀₀ = {c200_median:.2f}\n",
    "χ²/dof = {reduced_chi2:.2f}\"\"\"\n",
    "\n",
    "ax.text(0.02, 0.98, info_text, transform=ax.transAxes, \n",
    "        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
    "        fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Final summary plot with uncertainty bands created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0011b2",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "This notebook demonstrated a complete weak lensing profile fitting workflow using CLensPy:\n",
    "\n",
    "1. **Data Generation**: We created synthetic weak lensing observations with realistic noise levels\n",
    "2. **Maximum Likelihood Fitting**: We used scipy optimization to find the best-fit NFW parameters\n",
    "3. **Uncertainty Estimation**: We employed MCMC sampling to characterize parameter uncertainties\n",
    "4. **Visualization**: We created comprehensive plots showing the fit quality and parameter constraints\n",
    "\n",
    "### Key Results:\n",
    "- The fitting procedure successfully recovered the true halo parameters within uncertainties\n",
    "- The MCMC analysis provided robust error estimates and revealed parameter degeneracies\n",
    "- The reduced chi-squared value indicates a good fit to the data\n",
    "\n",
    "### Next Steps:\n",
    "This framework can be extended for:\n",
    "- Real observational data analysis\n",
    "- More complex halo models (e.g., triaxial, substructure)\n",
    "- Joint fitting of multiple observables (shear, magnification, etc.)\n",
    "- Systematic error modeling\n",
    "\n",
    "CLensPy provides a solid foundation for weak lensing analysis workflows!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
